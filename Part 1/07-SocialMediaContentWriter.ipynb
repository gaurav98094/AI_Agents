{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879e1c6d",
   "metadata": {},
   "source": [
    "## Social Media Content Writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31c8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install crewai\n",
    "# !pip install crewai-tools\n",
    "# !pip  install firecrawl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ebea830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from crewai import Agent, Task, Crew\n",
    "from crewai.flow.flow import Flow, start, listen\n",
    "\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai_client = openai.OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "159f49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('notebook6/config/planner_agents.yaml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('notebook6/config/planner_tasks.yaml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ecc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "class Tweet(BaseModel):\n",
    "    \"\"\"Represents an individual tweet in a thread\"\"\"\n",
    "    content: str\n",
    "    is_hook: bool = False \n",
    "    media_urls: Optional[list[str]] = []\n",
    "\n",
    "class Thread(BaseModel):\n",
    "    \"\"\"Represents a Twitter thread\"\"\"\n",
    "    topic: str \n",
    "    tweets: list[Tweet]\n",
    "\n",
    "class LinkedInPost(BaseModel):\n",
    "    \"\"\"Represents a LinkedIn post\"\"\"\n",
    "    content: str  # The main content of the post\n",
    "    media_url: str # Main image URL for the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eccc56f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/g/miniconda3/envs/agents/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:623: UserWarning: <built-in function callable> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from crewai_tools import DirectoryReadTool, FileReadTool \n",
    "\n",
    "all_tools = [DirectoryReadTool(), FileReadTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c92de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task\n",
    "\n",
    "draft_analyzer = Agent(config=agents_config['draft_analyzer'],\n",
    "                       tools=all_tools,\n",
    "                       llm = \"gpt-3.5-turbo\")\n",
    "\n",
    "analyze_draft = Task(config=tasks_config['analyze_draft'],\n",
    "                     agent=draft_analyzer\n",
    "                     )\n",
    "\n",
    "\n",
    "\n",
    "twitter_thread_planner = Agent(config=agents_config['twitter_thread_planner'],\n",
    "                               tools=all_tools,\n",
    "                               llm = \"gpt-3.5-turbo\")\n",
    "\n",
    "create_twitter_thread_plan = Task(config=tasks_config['create_twitter_thread_plan'],\n",
    "                                  agent=twitter_thread_planner,\n",
    "                                  output_pydantic=Thread)\n",
    "\n",
    "\n",
    "\n",
    "linkedin_post_planner = Agent(config=agents_config['linkedin_post_planner'],\n",
    "                              tools=all_tools,\n",
    "                              llm = \"gpt-3.5-turbo\")\n",
    "\n",
    "create_linkedin_post_plan = Task(config=tasks_config['create_linkedin_post_plan'],\n",
    "                                 agent=linkedin_post_planner,\n",
    "                                 output_pydantic=LinkedInPost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_planning_crew = Crew(\n",
    "    agents=[draft_analyzer, twitter_thread_planner],\n",
    "    tasks=[analyze_draft, create_twitter_thread_plan],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "linkedin_planning_crew = Crew (\n",
    "    agents=[draft_analyzer, linkedin_post_planner],\n",
    "    tasks=[analyze_draft, create_linkedin_post_plan],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "\n",
    "class ContentPlanningState(BaseModel):\n",
    "    \"\"\"\n",
    "    State for the content planning flow\n",
    "    \"\"\"\n",
    "    # URL of the blog to scrape\n",
    "    blog_post_url: str = \"https://www.dailydoseofds.com/ai-agents-crash-course-part-4-with-implementation/#demo-1-social-media-content-writer-flow\"\n",
    "    \n",
    "    # Path where the scraped content will be stored\n",
    "    draft_path: Path = \"assets/\"\n",
    "    \n",
    "    # Determines whether to create a Twitter or LinkedIn post \n",
    "    post_type: str = \"twitter\"  \n",
    "    \n",
    "    # Example Twitter threads for style reference\n",
    "    path_to_example_threads: str = \"assets/example_threads.txt\" \n",
    "    \n",
    "    # Example LinkedIn posts for reference\n",
    "    path_to_example_linkedin: str = \"assets/example_linkedin.txt\"\n",
    "\n",
    "\n",
    "\n",
    "from firecrawl import FirecrawlApp\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from crewai.flow.flow import Flow, start, listen, router, or_\n",
    "\n",
    "class CreateContentPlanningFlow(Flow[ContentPlanningState]):\n",
    "\n",
    "    @start()\n",
    "    def scrape_blog_post(self):\n",
    "        print(f\"# Fetching draft from: {self.state.blog_post_url}\")\n",
    "\n",
    "        # Initialize FireCrawl\n",
    "        app = FirecrawlApp(api_key=os.getenv(\"FIRECRAWL_API_KEY\"))\n",
    "        \n",
    "        # Scrape the blog post in Markdown and HTML format\n",
    "        scrape_result = app.scrape_url(self.state.blog_post_url,\n",
    "                                       params={'formats': ['markdown', 'html']})\n",
    "\n",
    "        # Extract the title (fallback to a UUID if not found)\n",
    "        try:\n",
    "            title = scrape_result['metadata']['title']\n",
    "        except Exception:\n",
    "            title = str(uuid.uuid4())\n",
    "\n",
    "        # Store the scraped content as a markdown file\n",
    "        self.state.draft_path = f'assets/{title}.md'\n",
    "        with open(self.state.draft_path, 'w') as f:\n",
    "            f.write(scrape_result['markdown'])\n",
    "\n",
    "        return self.state\n",
    "    \n",
    "    @router(scrape_blog_post)\n",
    "    def select_platform(self):\n",
    "        if self.state.post_type == \"twitter\":\n",
    "            return \"twitter\"\n",
    "        elif self.state.post_type == \"linkedin\":\n",
    "            return \"linkedin\"\n",
    "        \n",
    "\n",
    "    @listen(\"twitter\")\n",
    "    def twitter_draft(self):\n",
    "        print(f\"# Planning content for: {self.state.draft_path}\")\n",
    "    \n",
    "        # Execute the Twitter Planning Crew\n",
    "        result = twitter_planning_crew.kickoff(inputs={\n",
    "            'draft_path': self.state.draft_path, \n",
    "            'path_to_example_threads': self.state.path_to_example_threads\n",
    "        })\n",
    "    \n",
    "        print(f\"# Planned content for {self.state.draft_path}:\")\n",
    "    \n",
    "        # Print each tweet in the generated thread\n",
    "        for i, tweet in enumerate(result.pydantic.tweets):\n",
    "            print(f\"Tweet {i+1}: {tweet.content}\")\n",
    "            print(f\"Media URLs: {tweet.media_urls}\")\n",
    "            print(\"-\" * 100)\n",
    "    \n",
    "        return result\n",
    "\n",
    "    @listen(\"linkedin\")\n",
    "    def linkedin_draft(self):\n",
    "        print(f\"# Planning content for: {self.state.draft_path}\")\n",
    "    \n",
    "        # Execute the LinkedIn Planning Crew\n",
    "        result = linkedin_planning_crew.kickoff(inputs={\n",
    "            'draft_path': self.state.draft_path, \n",
    "            'path_to_example_linkedin': self.state.path_to_example_linkedin\n",
    "        })\n",
    "    \n",
    "        print(f\"# Planned content for {self.state.draft_path}:\")\n",
    "        print(f\"{result.pydantic.content}\")\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    @listen(or_(twitter_draft, linkedin_draft))\n",
    "    def save_plan(self, plan):\n",
    "        with open(f'output/draft.json', 'w') as f:\n",
    "            json.dump(plan.pydantic.model_dump(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = CreateContentPlanningFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d115609",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b50060",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
